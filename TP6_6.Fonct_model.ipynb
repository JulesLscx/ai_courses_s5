{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7e3248-72b9-4ee7-8984-3a202c4525dd",
   "metadata": {},
   "source": [
    "# TP6.6 - Construire des modèles complexes (Approche fonctionnelle)\n",
    "\n",
    "Keras propose une API qui permet de construire des modèles de DNN complexe en se basant sur une modélisation fonctionnelle.</br>\n",
    "Le modèle fonctionnelle est assez simple à appréhender, on l'écrit comme une fonction mathématique:\n",
    "\n",
    "$ x=tf.keras.layers.Input(10), y=f(x); z=(g(y); u=concat(f(x),g(y))$</br>\n",
    "Prenons par exemple le modèle: la couche de normalisation est concaténée avec la couche hidden 2.\n",
    "<figure>\n",
    "    <img src=\"../images/functionalModel.jpg\"  style=\"width:240px;height:300px;\" >\n",
    "</figure>\n",
    "\n",
    "input_ = tf.keras.layers.Input(X_train.shape[1])</br>\n",
    "normalized_input = tf.keras.layers.Normalization()(input_)</br>\n",
    "hidden1 = tf.keras.layers.Dense(????, activation=\"???\")(normalized_input)</br>\n",
    "hidden2 = tf.keras.layers.Dense(????, activation=\"????\")(hidden1)</br>\n",
    "concat = tf.keras.layers.Concatenate()([normalized_input, hidden2])</br>\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(concat)</br>\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])</br></br>\n",
    "\n",
    "\n",
    "\n",
    "On peut construire aisément des architectures sophistiquées. \n",
    "- On peut imaginer par exemple que les hidden couches 1 et 2 sont concaténées. \n",
    "- la Hidden 1 est remise à la sortie de hidden 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfa1670-5e84-4178-9a15-32e1dc4341b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jules\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a280f9-6d79-487e-ab3e-c549caeaf4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Define the true positives, false positives and false negatives\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "\n",
    "    # Calculate the precision and recall\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f201101-ccf6-4cfb-9dd7-420c7f597656",
   "metadata": {},
   "source": [
    "## Réseaux de neurones avec une sortie sigmoide  sigmoïde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e88d0-b028-4a0f-9163-e9eb8d2721cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 Le DataSet\n",
    "On utilisera le Dataset smoking, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224f9c20-7d25-4a60-b62b-d79a260992bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lecture du dataset n permet de limiter le nombre de lignes à lire\n",
    "# Pour faciliter les tests\n",
    "import pandas as pd\n",
    "def load_data(n):\n",
    "    data = pd.read_csv('../data/train.new.csv')\n",
    "    return data[0:n]\n",
    "genders = {\n",
    "    'M' : 0,\n",
    "    'F' : 1\n",
    "}\n",
    "def select_variables(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop('id', axis=1)\n",
    "    df = df.drop('country', axis=1)\n",
    "    df = df.replace(genders)\n",
    "    df['imc'] = df['weight(kg)'] / (df['height(cm)'] / 100) ** 2\n",
    "    #make some categorical variables\n",
    "    df['new_age'] = pd.cut(df['age'], 5, labels=False)\n",
    "    df['eyesight(right)'] = pd.cut(df['eyesight(right)'], 5, labels=False)\n",
    "    df['eyesight(left)'] = pd.cut(df['eyesight(left)'], 5, labels=False)\n",
    "    #make combinations of categorical variables\n",
    "    df['age_bmi'] = df['new_age'] * df['imc']\n",
    "    X = df.drop('smoking', axis=1)\n",
    "    y = df['smoking']\n",
    "    X = X.drop('age', axis=1)\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d49ef-0c17-4f4f-a9ab-d110920b02ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc688811-54db-4df7-b3a8-0312f1d94a39",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1. Split des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac974c-218e-485e-a851-933f72c32248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a688bc3-4ccd-49bc-8a33-935a90024994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## On peut utiliser une simple normalisation (x-mu)/ecart type)\n",
    "def normaliser(X_train, X_test):\n",
    "    mean = X_train.mean()\n",
    "    std  = X_train.std()\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test  = (X_test  - mean) / std\n",
    "\n",
    "    return X_train, X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ca125-9fa5-4ac3-8729-732d84a75f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Préparation ds données\n",
    "# le -1 du load_data(-1) veut dire on prend toutes les lignes \n",
    "data=load_data(-1)\n",
    "# sélectionner les variables\n",
    "X,y = select_variables(data)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "X_train, X_test = normaliser(X_train, X_test)\n",
    "print(\"X_train.shape\", X_train.shape, \"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f62bd1-cb02-49a1-b0c8-b89e9b07cfd1",
   "metadata": {},
   "source": [
    "## 3. Définition du modèle de régression linaire\n",
    "\n",
    "On définit un modèle avec deux branches\n",
    "- une branche : une réseau à 2 couches  à 50 neurones avec un relu\n",
    "- une branche : un réseau "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b81f3-ea81-4b56-814c-db9ba3591b11",
   "metadata": {},
   "source": [
    "#### 3.1 Un réseau de neurones complexe à plusieurs couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab508f00-2ff2-4012-a3b3-b3c78558ad5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "input_ = tf.keras.layers.Input(X_train.shape[1])\n",
    "layer1 = tf.keras.layers.Dense(128, activation='relu')(input_)\n",
    "layer2 = tf.keras.layers.Dense(64, activation='relu')(layer1)\n",
    "concatenated = tf.keras.layers.Concatenate()([input_, layer2])\n",
    "dropout = tf.keras.layers.Dropout(0.2)(concatenated)\n",
    "hiden_last = tf.keras.layers.Dense(32, activation='relu')(dropout)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hiden_last)\n",
    "model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "#Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss= 'BinaryCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbdee8-5bf3-4757-a4d3-2a25d5e3ab0e",
   "metadata": {},
   "source": [
    "### 4. Entrainement du modèle (Model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9aeb5-8e6e-4419-a7c9-5a1a7bfebd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entrainement du modele\n",
    "history  = model.fit(X_train, \n",
    "                     y_train, \n",
    "                     epochs=10, \n",
    "                     batch_size= 10, \n",
    "                     verbose=False,\n",
    "                     validation_data = (X_test, y_test))\n",
    "#model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df71a8-3dd6-4f46-bff2-4afc1a2f228d",
   "metadata": {},
   "source": [
    "### 5. Evaluation des performances du modèle \n",
    "Utilisation de  MAE = Mean Absolute Error (between the labels and predictions), \n",
    "la loss, le R2 score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494207c-f184-4c4a-b368-7569884f7605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])\n",
    "#print('Test f1 score :', score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73435425-e08a-4025-8853-133f33225f35",
   "metadata": {},
   "source": [
    "### Historique du Training (training history)\n",
    "Quel était le meilleur résultat prendant l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bff4d2-e606-43fd-92ac-7654528e85ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(history.params)\n",
    "print(history.history.keys())\n",
    "#print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca131e-eba8-4add-966a-86339922bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.DataFrame(data=history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038638bf-c390-4774-8252-5f7915482920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=10)\n",
    "plt.title('Loss Curves', fontsize=12)\n",
    "\n",
    "# Plotting the Accuracy curve\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(history.history['accuracy'], 'green', linewidth=2.0)\n",
    "plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Accuracy', fontsize=10)\n",
    "plt.title('Accuracy ', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c9d1b-5762-4b64-b7d8-9a916067c0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Get class labels\n",
    "y_classes = np.argmax(y_pred, axis=-1)\n",
    "#y_classes = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_classes)\n",
    "#disp= ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970ea05-7b2a-4856-8261-3b1462310721",
   "metadata": {},
   "source": [
    "### Save History and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21edbfc-6808-4c6e-aa48-b4b82cc05c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving:\n",
    "\n",
    "np.save('my_history_sd_1n.npy',history.history)\n",
    "#np.save('my_history_sd_MLP.npy',history.history)\n",
    "#np.save('my_history_Ld_1n.npy',history.history)\n",
    "#np.save('my_history_Ld_MLP.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a58ab-7c9e-423c-a19e-cdd04dfc651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading:\n",
    "history=np.load('my_history.sd_1n.npy',allow_pickle='TRUE').item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d3401-217c-43f9-b6e9-3e293b03fec7",
   "metadata": {},
   "source": [
    "### 6. Faire des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b239594-6ef1-4542-ab2d-56e4950e3dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Small Sata set\n",
    "my_data = [ -0.25, -0.75, 0.78]\n",
    "survived = 0\n",
    "my_data=np.array(my_data).reshape(1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf27468-2363-4225-b994-487363d7d482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict( my_data )\n",
    "print(\"Prediction : {:.2f} K$\".format(predictions[0][0]))\n",
    "print(\"Reality    : {:.2f} K$\".format(survived))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c806bc2-088d-4aa1-8a0e-89c22064792a",
   "metadata": {},
   "source": [
    "## Question:\n",
    "- Comparer les deux modèles (simple versus complexe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0d1ba-b4c4-4bdd-8ff5-fc8ed16539a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
